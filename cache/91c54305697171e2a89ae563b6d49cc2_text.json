{
  "text": "UNIVERSITÉ SIDI MOHAMED BEN ABDELLAH\nFaculté des Sciences - Fès\nDépartement d’Informatique\nUNIVERSITÉ SORBONNE PARIS NORD\nPartenariat International\nRAPPORT DE PROJET\nAssistant Intelligent RAG Multimodal\nRéalisé par :\nBouizdouzene Bilal\nFormation :\nMaster Web Intelligence et Data Science\nAnnée Universitaire 2025-2026\n10 août 2025\nTable des matières\n1 Introduction 3\n1.1 Contexte et objectifs du projet . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Présentation générale du système . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Architecture du système 4\n2.1 Description générale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2 Architecture du système . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2.1 Entrées utilisateur (texte, audio, fichiers) . . . . . . . . . . . . . . . 4\n2.2.2 Prétraitement des données . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2.3 Indexation et base documentaire (FAISS) . . . . . . . . . . . . . . . 5\n2.2.4 Recherche et reranking documentaire . . . . . . . . . . . . . . . . . 5\n2.2.5 Gestion de l’historique conversationnel . . . . . . . . . . . . . . . . 5\n2.2.6 Génération de réponse avec Gemini . . . . . . . . . . . . . . . . . . 5\n2.3 Flux global du traitement . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.4 Gestion de l’historique conversationnel . . . . . . . . . . . . . . . . . . . . 6\n3 Gestion des données et entraînement 7\n3.1 Sources des données (dataset) . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.2 Extraction et segmentation sémantique (chunking) . . . . . . . . . . . . . . 7\n3.3 Création des embeddings (modèle sentence-transformers) . . . . . . . . . . 8\n3.4 Construction et entraînement de l’index FAISS . . . . . . . . . . . . . . . . 8\n3.5 Mise à jour et gestion dynamique de l’index . . . . . . . . . . . . . . . . . 8\n4 Technologies et outils utilisés 9\n4.1 Langages et frameworks . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n4.2 Modèles d’IA (Whisper, Gemini, sentence-transformers) . . . . . . . . . . . 9\n4.3 Vectorisation et recherche sémantique (FAISS) . . . . . . . . . . . . . . . . 10\n4.4 Base de données et gestion de l’historique . . . . . . . . . . . . . . . . . . . 10\n5 Résultats et démonstration 11\n5.1 Exemples de questions et réponses . . . . . . . . . . . . . . . . . . . . . . . 11\n5.1.1 Questions générales . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1\n5.1.2 Questions multimodales avec PDF (upload de fichiers) . . . . . . . 12\n5.1.3 Questions multimodales avec image (OCR) . . . . . . . . . . . . . . 13\n5.1.4 Questions multimodales avec audio (Whisper) . . . . . . . . . . . . 13\n5.1.5 Visualisation du contexte documentaire utilisé . . . . . . . . . . . . 14\n5.1.6 Gestion de l’historique et continuité de la conversation . . . . . . . 14\n6 Limites et perspectives d’amélioration 15\n6.1 Limites actuelles du système . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n6.2 Améliorations futures possibles . . . . . . . . . . . . . . . . . . . . . . . . 16\n7 Conclusion 17\n2\nCHAPITRE 1\nIntroduction\n1.1 Contexte et objectifs du projet\nAvec l’évolution rapide des technologies d’intelligence artificielle, les systèmes de dia-\nlogue automatisés ont gagné en importance, notamment dans les applications d’assistance\nvirtuelle,supportclientettraitementintelligentdel’information.Ceprojetviseàdévelop-\nper un chatbot intelligent basé sur la méthode Retrieval-Augmented Generation (RAG),\ncapable de traiter des questions posées en texte, audio ou fichiers, et d’exploiter une base\ndocumentaire riche pour fournir des réponses précises et contextualisées.\nL’objectif principal est de concevoir un système multimodal qui intègre la reconnais-\nsance vocale (via Whisper), la recherche documentaire sémantique (via FAISS et embed-\ndings HuggingFace), et la génération de texte avancée (via le modèle Gemini 2.5 Pro),\ntout en assurant la gestion d’un historique conversationnel pour une meilleure continuité.\n1.2 Présentation générale du système\nLe système développé fonctionne selon un pipeline structuré : les données entrantes\n(texte, audio ou fichiers) sont d’abord prétraitées et transformées en format exploitable.\nLes contenus textuels extraits sont indexés dans une base vectorielle FAISS après avoir été\nsegmentéssémantiquementetvectorisésgrâceàunmodèledetype sentence-transformers .\nLorsqu’une question est posée, le système effectue une recherche de documents perti-\nnents dans l’index FAISS, applique un reranking pour prioriser les meilleurs extraits, puis\ngénère une réponse enrichie en tenant compte de l’historique récent de la conversation,\ngarantissant ainsi une interaction fluide et cohérente.\n3\nCHAPITRE 2\nArchitecture du système\n2.1 Description générale\nL’architecture du chatbot RAG multimodal est conçue pour intégrer plusieurs com-\nposants clés permettant le traitement efficace de différentes formes d’entrée utilisateur,\nainsi que la génération de réponses précises et contextualisées.\nLe système est organisé autour d’un pipeline principal où les données entrantes (texte,\naudio, fichiers) sont prétraitées, indexées, et utilisées pour la recherche d’informations\naugmentée par génération (RAG).\n2.2 Architecture du système\nCette section décrit en détail l’architecture du système, depuis la réception des entrées\nutilisateur jusqu’à la génération de la réponse finale.\n2.2.1 Entrées utilisateur (texte, audio, fichiers)\nLe système accepte plusieurs types d’entrées utilisateur :\n—Texte: Questions saisies directement par l’utilisateur via l’interface.\n—Audio: Enregistrements vocaux transcrits en texte grâce au modèle Whisper.\n—Fichiers : Documents (PDF, DOCX, images) uploadés et dont le contenu textuel\nest extrait.\nCes différentes modalités permettent une interaction riche et flexible avec l’assistant.\n2.2.2 Prétraitement des données\nAvanttouteutilisation,lesdonnéesbrutessubissentplusieursétapesdeprétraitement:\n—Extraction de texte : Utilisation de bibliothèques spécialisées pour extraire\nle contenu textuel des fichiers uploadés (PyPDF2, python-docx, Tesseract OCR,\nWhisper).\n4\n—Nettoyage et normalisation : Suppression des caractères inutiles, correction de\nl’encodage, découpage en passages cohérents (chunking sémantique) pour faciliter\nla recherche.\n—Création de métadonnées : Attribution d’identifiants uniques aux documents,\nenregistrement des titres et sources pour un suivi précis.\n2.2.3 Indexation et base documentaire (FAISS)\nLes documents extraits sont vectorisés à l’aide d’un modèle d’embeddings pré-entraîné\n(sentence-transformers/all-MiniLM-L6-v2) puis stockés dans une base de données vecto-\nrielle FAISS pour des recherches efficaces.\n—Chargement et sauvegarde : L’index FAISS est chargé au démarrage de l’ap-\nplication et sauvegardé après chaque modification.\n—Gestion dynamique : Possibilité d’ajouter ou de supprimer des documents à la\nvolée, avec contrôle des doublons grâce aux identifiants uniques.\n2.2.4 Recherche et reranking documentaire\nLorsqu’une question est posée, le système interroge la base FAISS pour retrouver les\ndocuments les plus pertinents selon la similarité vectorielle. Ces documents sont ensuite\nréordonnés (reranking) avec un cross-encoder pour améliorer la pertinence finale des ré-\nsultats.\n2.2.5 Gestion de l’historique conversationnel\nL’historique des échanges est stocké en base de données, permettant de conserver le\ncontexte sur plusieurs tours de dialogue. Cela garantit la cohérence des réponses et évite\nla perte de mémoire liée à un redémarrage ou une nouvelle session.\n2.2.6 Génération de réponse avec Gemini\nLe modèle Gemini 2.5 Pro est utilisé pour générer des réponses détaillées et contex-\ntualisées, en combinant les informations issues des documents retrouvés et l’historique\nconversationnel. Un résumé simplifié est également produit pour faciliter la compréhen-\nsion.\n2.3 Flux global du traitement\nLe processus complet suit la séquence suivante :\n1. Réception de la question (texte, audio transcrit, ou question + fichier).\n2. Extraction et prétraitement du contenu des fichiers si nécessaire.\n5\n3. Ajout du contenu indexé dans FAISS avec métadonnées.\n4. Recherche des documents pertinents dans FAISS et reranking.\n5. Récupération de l’historique conversationnel depuis la base de données.\n6. Construction du prompt combinant la question, les documents et l’historique.\n7. Génération de la réponse par Gemini.\n8. Enregistrement de la nouvelle interaction dans l’historique.\nCette architecture modulaire assure une grande flexibilité, évolutivité et robustesse du\nsystème.\nFigure 2.1 – Schéma de l’architecture du système montrant le flux de données du ques-\ntionnement utilisateur jusqu’à la réponse générée.\n2.4 Gestion de l’historique conversationnel\nLe système conserve un historique structuré des échanges utilisateur-assistant, stocké\ndans une base de données. Cette mémoire contextuelle permet de maintenir la cohérence\ndes dialogues, même après redémarrage du système, et d’améliorer la pertinence des ré-\nponses en tenant compte du fil de la discussion.\n6\nCHAPITRE 3\nGestion des données et entraînement\nCe chapitre décrit le processus complet de gestion des données, depuis leur acquisi-\ntion jusqu’à la construction et la mise à jour de l’index FAISS utilisé pour la recherche\ndocumentaire.\n3.1 Sources des données (dataset)\nLes données proviennent de diverses sources, incluant :\n— Documents utilisateurs : fichiers PDF, DOCX, images ou autres documents uploa-\ndés par les utilisateurs.\n— Bases documentaires internes : collections de documents textuels pertinents pour\nle domaine d’application.\n— Données externes : sources publiques ou privées, pouvant être intégrées selon les\nbesoins.\nCes données sont la matière première indispensable à la constitution d’une base docu-\nmentaire riche et utile pour l’assistant.\n3.2 Extractionetsegmentationsémantique(chunking)\nPour optimiser la recherche, les documents complets sont segmentés en passages sé-\nmantiques cohérents appelés chunks. Ce découpage est réalisé en tenant compte :\n— Du nombre maximal de tokens par chunk (environ 500 tokens).\n— Duchevauchemententrechunks(overlapde100tokens)pourmaintenirlecontexte.\n— De la cohérence sémantique afin que chaque chunk contienne une idée ou un thème\nhomogène.\nCettesegmentationaméliorelagranularitédesrecherchesetlapertinencedesrésultats.\n7\n3.3 Créationdesembeddings(modèlesentence-transformers)\nChaque chunk est converti en un vecteur numérique de faible dimension à l’aide d’un\nmodèle d’embeddings pré-entraîné, ici sentence-transformers/all-MiniLM-L6-v2 . Ce\nmodèleencodelasignificationsémantiquedestextes,permettantdecomparerefficacement\nla similarité entre question et documents.\n3.4 Construction et entraînement de l’index FAISS\nLes vecteurs d’embeddings sont indexés dans la base vectorielle FAISS, qui permet\nune recherche rapide et scalable dans des bases de données volumineuses.\n—Construction initiale : Création de l’index à partir des documents existants.\n—Entraînement : FAISS propose des algorithmes d’indexation (ex. IVF, HNSW)\nnécessitant parfois une phase d’entraînement pour optimiser les structures de re-\ncherche.\n—Sauvegarde : L’index entraîné est sauvegardé localement pour réutilisation.\n3.5 Mise à jour et gestion dynamique de l’index\nLe système supporte l’ajout ou la suppression dynamique de documents, avec des\nmécanismes pour :\n— Vérifier la présence d’un document via un identifiant unique afin d’éviter les dou-\nblons.\n— Ajouter les nouveaux chunks vectorisés à l’index existant.\n— Réentraîner ou réorganiser l’index FAISS si nécessaire pour maintenir une perfor-\nmance optimale.\n— Sauvegarder régulièrement l’état de l’index.\nCette gestion dynamique assure que la base documentaire est toujours à jour et cohé-\nrente avec les contenus disponibles pour la recherche.\n8\nCHAPITRE 4\nTechnologies et outils utilisés\nCe chapitre présente les principaux langages, frameworks, modèles d’IA et outils qui\ncomposent l’architecture du projet.\n4.1 Langages et frameworks\nLe projet est principalement développé avec les technologies suivantes :\n—Python : langage principal pour le backend, gestion des modèles IA, traitement\ndes données, et orchestration du système.\n—Flask: micro-framework web léger utilisé pour construire l’API backend et gérer\nles requêtes utilisateur.\n—JavaScript / HTML / CSS : technologies frontend pour l’interface utilisateur,\nincluant la gestion des interactions, l’upload de fichiers, et l’enregistrement audio.\n—SQLAlchemy : ORM utilisé pour la gestion de la base de données SQLite, facili-\ntant la persistance de l’historique conversationnel.\n4.2 Modèlesd’IA(Whisper,Gemini,sentence-transformers)\nLe projet intègre plusieurs modèles d’intelligence artificielle pour différentes tâches :\n—Whisper (OpenAI) : modèle de reconnaissance vocale automatique (ASR) utilisé\npour la transcription des entrées audio en texte.\n—Gemini2.5Pro (GoogleGenerativeAI):modèledegénérationdelangagenaturel\nemployé pour générer les réponses aux questions en combinant les informations\nissues des documents et de l’historique.\n—Sentence-transformers : modèles spécialisés dans la création d’embeddings sé-\nmantiques pour la vectorisation des documents et des requêtes, facilitant la re-\ncherche par similarité.\n9\n4.3 Vectorisation et recherche sémantique (FAISS)\n—FAISS(Facebook AI Similarity Search) : bibliothèque open-source optimisée pour\nla recherche rapide de vecteurs similaires dans de grandes bases de données. Elle\npermet :\n— L’indexation efficace des embeddings.\n— La recherche par similarité sémantique.\n— La gestion dynamique de l’index avec ajout ou suppression de documents.\n4.4 Base de données et gestion de l’historique\nPour assurer la continuité des conversations et le suivi des interactions utilisateur, le\nprojet utilise :\n—SQLite : base de données légère embarquée pour stocker l’historique des échanges.\n—SQLAlchemy : outil ORM facilitant l’interaction avec SQLite, permettant la\nrécupération et l’insertion des messages dans la table historique.\n—Gestion de sessions et threads : chaque conversation est associée à un iden-\ntifiant de session et de thread pour organiser l’historique de manière cohérente et\nmulti-utilisateurs.\n10\nCHAPITRE 5\nRésultats et démonstration\nCe chapitre illustre la performance et les fonctionnalités principales du système à\ntravers des exemples concrets et des visualisations.\n5.1 Exemples de questions et réponses\nPour valider la qualité des réponses générées, plusieurs questions variées ont été posées\nau système, portant sur des documents préalablement indexés ou des questions directes.\nVoici quelques exemples :\n5.1.1 Questions générales\n(a)\n (b)\n (c)\n(d)\n (e)\nFigure 5.1 – chat normal avec RAG.\n11\n5.1.2 Questions multimodales avec PDF (upload de fichiers)\n(a)\n (b)\n(c)\n (d)\n(e)\n (f)\n(g)\n (h)\nFigure 5.2 – Question avec PDF\n12\n5.1.3 Questions multimodales avec image (OCR)\n(a)\n (b)\n(c)\n (d)\nFigure 5.3 – Question avec image\n5.1.4 Questions multimodales avec audio (Whisper)\n(a)\n (b)\n (c)\n(d)\n (e)\nFigure 5.4 – Question avec audio\nCes exemples démontrent la capacité du système à comprendre et exploiter différentes\nsources d’information pour fournir des réponses pertinentes et contextualisées.\n13\n5.1.5 Visualisation du contexte documentaire utilisé\nLe système met en évidence les extraits documentaires ayant servi à la génération des\nréponses. Cette transparence est assurée par :\n— L’affichage des titres des documents et des indices des chunks (segments) utilisés.\n— Un aperçu textuel (quelques centaines de caractères) de chaque chunk exploité\ndans la réponse.\n— La possibilité pour l’utilisateur de vérifier l’origine des informations fournies, aug-\nmentant la confiance dans la réponse.\nCette fonctionnalité est cruciale pour les applications professionnelles où la traçabilité\ndes sources est essentielle.\n5.1.6 Gestion de l’historique et continuité de la conversation\nLe projet intègre un module de gestion d’historique conversationnel performant qui\npermet :\n— La sauvegarde des échanges entre l’utilisateur et l’assistant dans une base de don-\nnées SQLite, garantissant la persistance même en cas de redémarrage du système.\n— La récupération des derniers tours de dialogue, permettant au modèle de conserver\nle contexte et d’offrir des réponses cohérentes dans la continuité des échanges.\n— La prise en compte de l’historique dans la formulation des prompts, améliorant la\nqualité des réponses et évitant la perte de contexte.\n— La gestion multi-utilisateurs et multi-sessions, avec organisation par identifiants de\nsession et de thread.\nFigure 5.5 – Exemple des chunks utilisées.\nGrâce à ce système, l’expérience utilisateur est fluide, et la conversation appa-\nraît naturelle et contextualisée, comparable à un échange humain.\n14\nCHAPITRE 6\nLimites et perspectives\nd’amélioration\nCe chapitre analyse les principales limites rencontrées dans le projet ainsi que\nles pistes envisagées pour son amélioration et son évolution.\n6.1 Limites actuelles du système\nMalgré ses nombreuses fonctionnalités, le système présente plusieurs limitations\nimportantes :\n—Capacité limitée de mémoire contextuelle : La gestion de l’historique\nconversationnel est restreinte à un nombre fixe de derniers échanges, ce qui\npeut entraîner une perte progressive de contexte sur de longues conversations.\n—Dépendance aux performances de l’index FAISS : La qualité et la rapi-\ndité des recherches dépendent fortement de la taille et de la qualité de l’index.\nPour de très grands volumes de documents, l’index peut devenir lourd à mani-\npuler sans optimisation supplémentaire.\n—Qualité variable des réponses : La génération par Gemini peut parfois\nproduire des réponses trop générales ou hors sujet, notamment lorsque les do-\ncuments indexés ne couvrent pas précisément la question posée.\n—Traitement des fichiers limité : Le système prend en charge plusieurs for-\nmats (PDF, DOCX, images, audio), mais certains types ou fichiers complexes\npeuvent poser problème lors de l’extraction de texte ou la segmentation.\n—Entraînementetmiseàjourdel’indexnonautomatisés: L’indexFAISS\nest mis à jour manuellement via l’ajout de documents. Un pipeline d’automa-\ntisation ou d’apprentissage continu serait bénéfique.\n15\n6.2 Améliorations futures possibles\nPlusieurs axes d’amélioration sont envisageables pour rendre le système plus\nrobuste, performant et polyvalent :\n—Extensiondelamémoireconversationnelle: Intégrerdestechniquesavan-\ncées de gestion du contexte (ex : mémoire longue, résumé dynamique) pour\nconserver davantage d’informations pertinentes au fil des échanges.\n—Optimisation et scalabilité de l’index FAISS : Implémenter des stratégies\nde sharding, compression ou utilisation de bases vectorielles distribuées pour\ngérer efficacement de très grands corpus documentaires.\n—Amélioration du reranking : Intégrer des modèles cross-encoder plus per-\nformants ou des méthodes hybrides pour améliorer la pertinence des documents\nsélectionnés.\n—Automatisation du pipeline d’indexation : Développer un système d’in-\ngestion automatique des documents avec extraction, chunking, embedding et\nmise à jour de l’index en continu.\n—Support étendu de formats et multimodalité : Améliorer l’extraction de\ndonnées depuis différents formats complexes et intégrer des modèles multimo-\ndaux plus avancés (ex : Vision-Language Models).\n—Interface utilisateur et expérience : Ajouter des fonctionnalités interac-\ntives, un tableau de bord de suivi des conversations, et une meilleure gestion\ndes erreurs pour une utilisation professionnelle.\nCes améliorations permettraient au système de mieux répondre aux exigences\nd’applications industrielles et de recherche avancée, tout en offrant une expérience\nutilisateur enrichie.\n16\nCHAPITRE 7\nConclusion\nCe projet a permis de développer un assistant intelligent reposant sur une archi-\ntecture avancée de Retrieval-Augmented Generation (RAG), combinant indexation\ndocumentaire via FAISS, gestion dynamique des documents, et génération de ré-\nponses à l’aide du modèle Gemini. La prise en charge multimodale des entrées\n(texte, audio, fichiers) ainsi que la gestion d’un historique conversationnel ont été\ndes points clés pour garantir une expérience utilisateur fluide et contextuelle.\nL’approche modulaire adoptée facilite la maintenance et l’évolution du sys-\ntème, notamment par l’intégration de techniques de reranking et de segmentation\nsémantiquepouroptimiserlapertinencedesrésultats.Néanmoins,certaineslimites\nliées à la mémoire contextuelle, la gestion de l’index et la qualité des réponses dé-\nmontrent les opportunités d’amélioration, notamment vers plus d’automatisation\net de scalabilité.\nCe travail ouvre la voie à des applications variées dans le domaine de l’assis-\ntance virtuelle, la recherche documentaire intelligente, et le traitement multimodal\ndes données. Les futures évolutions viseront à renforcer la robustesse, la précision\net la richesse fonctionnelle du système, en tirant parti des avancées récentes en\nintelligence artificielle et traitement du langage naturel.\n17"
}